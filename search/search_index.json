{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to VectorSearch","text":"<p>VectorSearch (VS) is a self-optimizing hybrid indexing system for scalable and memory-efficient vector retrieval.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Quantization-based candidate filtering  </li> <li>Lightweight graph refinement</li> <li>Semantic embedding alignment </li> <li>Semantic embedding alignment  </li> <li>Multi-vector query support  </li> <li>Dynamic hyperparameter tuning  </li> <li>Caching and memory-mapped storage   </li> </ul> <p>Start with Getting Started</p>"},{"location":"#system-design-overview","title":"System Design Overview","text":"<p>ectorSearch introduces a modular architecture that integrates:</p> <ul> <li>Semantic embedding alignment</li> <li>Multi-vector query support</li> <li>Caching and memory mapping</li> <li>Dynamic hyperparameter tuning</li> </ul> <p>The system executes a coarse-to-fine retrieval pipeline, leveraging quantized vector search for rapid candidate selection, followed by graph-based reranking for refined accuracy. This design enables high recall with minimal latency and adapts to diverse workloads without index reconstruction.</p>"},{"location":"benchmarks/","title":"Benchmarks","text":"<p>This section presents detailed evaluations of VectorSearch across multiple benchmark scenarios, highlighting performance within static and dynamic indexing setups, as well as ablation studies on system design components.</p> <p>We evaluate the system using standard datasets such as Glove1.2M, SIFT10M, Deep1M, and News, and compare to state-of-the-art baselines including FAISS, HNSWlib, LVQ, and Milvus.</p>"},{"location":"benchmarks/#sections","title":"Sections","text":"<ul> <li> <p>Static Indexing:   Evaluates precision, memory usage, and query latency on pre-built indexes using static datasets.</p> </li> <li> <p>Dynamic Indexing:   Measures update latency, scalability, and post-insertion accuracy for real-time index updates without reconstruction.</p> </li> <li> <p>Ablation Studies:   Evaluates the impact of quantization, graph reranking, and memory optimization strategies on system performance.</p> </li> </ul>"},{"location":"benchmarks/#benchmark-summary-across-all-tasks","title":"\ud83d\udcca Benchmark Summary (Across All Tasks)","text":"Method Dataset Precision@10 Recall@10 Latency (ms) Memory (GiB) FAISS-IVFPQ Glove1.2M 0.78 0.71 12 1.2 HNSWlib Glove1.2M 0.85 0.79 20 2.6 LVQ [VLDB'23] Deep1M 0.88 0.84 15 1.8 VectorSearch (Ours) All 0.92 0.87 11 1.0 <p>Full tables and visual comparisons are included in each section linked above.</p>"},{"location":"getting_started/","title":"Getting Started with VectorSearch (VS)","text":"<p>VectorSearch (VS) is a self-optimizing hybrid indexing system designed for scalable and memory-efficient vector retrieval. This guide walks you through setting up the system and running a sample search on a small dataset.</p>"},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<p>Ensure your environment is running Ubuntu (20.04 or later). The instructions below are tested on an Azure VM (Standard_E64ds_v4), but they work in any compatible Linux setup.</p>"},{"location":"getting_started/#installation","title":"\ud83d\udce6 Installation","text":""},{"location":"getting_started/#1-install-system-dependencies","title":"1. Install System Dependencies","text":"<pre><code>sudo apt-get update &amp;&amp; sudo apt-get install -y \\\n  build-essential cmake g++ make libomp-dev \\\n  python3 python3-pip python3-venv python3-dev\n</code></pre>"},{"location":"multi_vector/","title":"\ud83d\udd0d Multi-Vector Retrieval (C++ Implementation)","text":"<p>This page documents the C++ implementation of multi-vector retrieval and evaluation in the VectorSearch system.</p>"},{"location":"multi_vector/#overview","title":"Overview","text":"<p>We implemented multi-vector aggregation in C++ to improve retrieval robustness when a query is represented by multiple semantically similar vectors...</p>"},{"location":"multi_vector/#how-it-works","title":"\u2699\ufe0f How It Works","text":""},{"location":"multi_vector/#query-aggregation","title":"\ud83d\udd39 Query Aggregation","text":"<p>A set of query vectors (e.g., ID 0\u20134) is treated as one logical query. Each base vector is scored based on the average L2 distance to these multiple queries.</p> <p>```cpp for (int i = 0; i &lt; prep.data.N; ++i) {     float total_dist = 0.0f;     for (const auto&amp; qvec : multi_query) {         total_dist += cal_distSqrt(qvec.data(), prep.data.val[i], prep.data.dim);     }     score_all[i] = { total_dist / multi_query.size(), i }; }</p>"},{"location":"visualizations/","title":"Visualizations","text":""},{"location":"visualizations/#vectorsearch-vs-system-architecture","title":"VectorSearch (VS) System Architecture","text":""},{"location":"visualizations/#embedding-visualization","title":"Embedding Visualization","text":"<p>2D visualization of embeddings by topic (Health, Technology, Science), demonstrating how semantic clusters are separated in reduced space.</p>"},{"location":"benchmarks/Overview/","title":"Benchmarks","text":"<p>This section presents detailed evaluations of VectorSearch across multiple benchmark scenarios, highlighting performance within static and dynamic indexing setups, as well as ablation studies on system design components.</p> <p>We evaluate the system using standard datasets such as Glove1.2M, SIFT10M, Deep1M, and News, and compare to state-of-the-art baselines including FAISS, HNSWlib, LVQ, and Milvus.</p>"},{"location":"benchmarks/Overview/#sections","title":"Sections","text":"<ul> <li> <p>Static Indexing:   Evaluates precision, memory usage, and query latency on pre-built indexes using static datasets.</p> </li> <li> <p>Dynamic Indexing:   Measures update latency, scalability, and post-insertion accuracy for real-time index updates without reconstruction.</p> </li> <li> <p>Ablation Studies:   Evaluates the impact of quantization, graph reranking, and memory optimization strategies on system performance.</p> </li> </ul>"},{"location":"benchmarks/Overview/#benchmark-summary-across-all-tasks","title":"\ud83d\udcca Benchmark Summary (Across All Tasks)","text":"Method Dataset Precision@10 Recall@10 Latency (ms) Memory (GiB) FAISS-IVFPQ Glove1.2M 0.78 0.71 12 1.2 HNSWlib Glove1.2M 0.85 0.79 20 2.6 LVQ [VLDB'23] Deep1M 0.88 0.84 15 1.8 VectorSearch (Ours) All 0.92 0.87 11 1.0 <p>Full tables and visual comparisons are included in each section linked above.</p>"},{"location":"benchmarks/dynamic_indexing/","title":"Dynamic Indexing","text":"<p>This section describes the dynamic retrieval mechanism implemented in VectorSearch, focusing on runtime adaptability without reconstructing the index.</p>"},{"location":"benchmarks/dynamic_indexing/#what-we-implemented","title":"What We Implemented","text":"<p>We developed a configurable retrieval pipeline that supports real-time parameter tuning during query execution. The key features include:</p> <ul> <li>Dynamic adjustment of search parameters such as <code>nprobe</code> (coarse search) and <code>efSearch</code> (reranking depth)</li> <li>A two-stage retrieval process:</li> <li>Coarse candidate selection </li> <li>Fine-grained reranking </li> <li>Evaluation of system behavior under various runtime settings without rebuilding the index</li> </ul>"},{"location":"benchmarks/dynamic_indexing/#evaluation-metrics","title":"\ud83d\udcc8 Evaluation Metrics","text":"<ul> <li>Recall@10 \u2013 Accuracy of top-k retrieved results  </li> <li>Query Throughput (QPS) \u2013 Queries processed per second  </li> <li>Memory Usage (GiB) \u2013 Memory footprint during retrieval  </li> <li>Latency (s) \u2013 Total retrieval time per query batch  </li> </ul>"},{"location":"benchmarks/dynamic_indexing/#experimental-setup","title":"Experimental Setup","text":"<ul> <li>Datasets: SIFT10M and Deep1M  </li> <li>Query Count: 10,000 queries per configuration  </li> <li>Tunable Parameters:  </li> <li><code>nprobe</code> (1\u201340) for candidate selection  </li> <li><code>efSearch</code> (16\u2013128) for reranking scope  </li> </ul>"},{"location":"benchmarks/dynamic_indexing/#result-highlights","title":"\ud83d\udcca Result Highlights","text":"Config QPS Recall@10 Memory (GiB) Latency (s) A 175.6 0.8820 0.135 5.69 B 148.1 0.8990 0.139 6.75 C 102.3 0.9174 0.142 9.78 D 65.2 0.9325 0.145 15.34 <p>These results highlight how retrieval accuracy and latency can be balanced dynamically by tuning query-time parameters\u2014without modifying the index.</p>"},{"location":"benchmarks/dynamic_indexing/#summary","title":"Summary","text":"<p>VectorSearch enables dynamic indexing through real-time adjustment of search configurations. </p>"},{"location":"benchmarks/dynamic_indexing/#configuration-breakdown-figure-8","title":"\ud83d\udd22 Configuration Breakdown (Figure 8)","text":"<p>The following configurations represent the right-most points of the QPS\u2013Recall@10 trade-off curve shown in Figure 8. Each setting corresponds to a different <code>nprobe</code> value with a fixed reranking depth (<code>efSearch = 128</code>), reflecting different runtime recall levels.</p> nprobe efSearch Recall@10 QPS Corresponds to 5 128 0.999 1899.8 VS (R=5) 10 128 1.000 1578.6 VS (R=10) 20 128 1.000 1244.2 VS (R=20) 40 128 0.999 923.6 VS (R=40)"},{"location":"benchmarks/static_indexing/","title":"Benchmarks","text":"<p>This section presents detailed evaluations of VectorSearch across multiple benchmark scenarios, highlighting performance within static and dynamic indexing setups, as well as ablation studies on system design components.</p> <p>We evaluate the system using standard datasets such as Glove1.2M, SIFT10M, Deep1M, and News, and compare to state-of-the-art baselines including FAISS, HNSWlib, LVQ, and Milvus.</p>"},{"location":"benchmarks/static_indexing/#sections","title":"Sections","text":"<ul> <li> <p>Static Indexing:   Evaluates precision, memory usage, and query latency on pre-built indexes using static datasets.</p> </li> <li> <p>Dynamic Indexing:   Measures update latency, scalability, and post-insertion accuracy for real-time index updates without reconstruction.</p> </li> <li> <p>Ablation Studies:   Evaluates the impact of quantization, graph reranking, and memory optimization strategies on system performance.</p> </li> </ul>"},{"location":"benchmarks/static_indexing/#benchmark-summary-across-all-tasks","title":"\ud83d\udcca Benchmark Summary (Across All Tasks)","text":"Method Dataset Precision@10 Recall@10 Latency (ms) Memory (GiB) FAISS-IVFPQ Glove1.2M 0.78 0.71 12 1.2 HNSWlib Glove1.2M 0.85 0.79 20 2.6 LVQ [VLDB'23] Deep1M 0.88 0.84 15 1.8 VectorSearch (Ours) All 0.92 0.87 11 1.0 <p>Full tables and visual comparisons are included in each section linked above.</p>"}]}